{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement libtensorflow (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for libtensorflow\u001b[0m\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libtensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qg/sbp5jd6x62g54q__k8821dxw0000gn/T/ipykernel_1430/1865938038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libtensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Conv2DTranspose, Activation, Reshape, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dropout, Concatenate, Dense, LeakyReLU, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "MODEL_NAME = 'DCGAN'\n",
    "DATA_BASE_DIR = 'dataset/images/'\n",
    "OUTPUT_PATH = os.path.join('outputs', MODEL_NAME)\n",
    "TRAIN_LOGDIR = os.path.join(\"logs\", \"tensorflow\", MODEL_NAME, 'train_data') # Sets up a log directory.\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "    \n",
    "TARGET_IMG_SIZE = 64 # Scale images to this size\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NOISE_DIM = 100\n",
    "LAMBDA = 10 # For gradient penalty\n",
    "\n",
    "EPOCHs = 40\n",
    "CURRENT_EPOCH = 1 # Epoch start from\n",
    "SAVE_EVERY_N_EPOCH = 10 # Save checkpoint at every n epoch\n",
    "\n",
    "N_CRITIC = 3 # Train critic(discriminator) n times then train generator 1 time.\n",
    "LR = 1e-4\n",
    "MIN_LR = 0.000001 # Minimum value of learning rate\n",
    "DECAY_FACTOR=1.00004 # learning rate decay factor\n",
    "\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "# Modify the directory to the path of your dataset\n",
    "list_ds = tf.data.Dataset.list_files('../../dataset/img_align_celeba/img_align_celeba/*')\n",
    "\n",
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28cf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    '''\n",
    "        normalizing the images to [-1, 1]\n",
    "    '''\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image\n",
    "\n",
    "def preprocess_image(file_path):\n",
    "    images = tf.io.read_file(file_path)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    images = tf.image.decode_jpeg(images, channels=3)\n",
    "    images = tf.image.resize(images, (TARGET_IMG_SIZE, TARGET_IMG_SIZE),\n",
    "                           method='bicubic', antialias=True)\n",
    "    images = normalize(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list_ds.map(preprocess_image).shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = next(iter(train_data))\n",
    "plt.title('Sample')\n",
    "plt.imshow(np.clip(sample_img[0] * 0.5 + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5456da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare models\n",
    "\n",
    "# You could also try layer normalization instead of batch normalization\n",
    "\n",
    "def CGAN_generator(input_z_shape=NOISE_DIM):\n",
    "    '''\n",
    "        DCGAN like generator architecture\n",
    "    '''\n",
    "    input_z_layer = Input(input_z_shape)\n",
    "    \n",
    "    z = Dense(4*4*512, use_bias=False)(input_z_layer)\n",
    "    z =Reshape((4, 4, 512))(z)\n",
    "    \n",
    "    x = Conv2DTranspose(512, (4, 4), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(z)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    output = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation=\"tanh\",\n",
    "                             kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    \n",
    "    model = Model(inputs=input_z_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "def CGAN_discriminator(input_x_shape=(TARGET_IMG_SIZE, TARGET_IMG_SIZE, 3)):\n",
    "    '''\n",
    "        DCGAN like discriminator architecture\n",
    "    '''\n",
    "    input_x_layer = Input(input_x_shape)\n",
    "    \n",
    "    x = Conv2D(64, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(input_x_layer)\n",
    "    #x = LayerNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    #x = LayerNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    #x = LayerNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(512, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    #x = LayerNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(1, (4, 4), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    output = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=input_x_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CGAN_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d667a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()\n",
    "# Require extra packages to plot model \n",
    "# plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = CGAN_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()\n",
    "# Require extra packages to plot model \n",
    "# plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers \n",
    "D_optimizer = Adam(learning_rate=LR, beta_1=0.5)\n",
    "G_optimizer = Adam(learning_rate=LR, beta_1=0.5)\n",
    "\n",
    "def learning_rate_decay(current_lr, decay_factor=DECAY_FACTOR):\n",
    "    '''\n",
    "        Calculate new learning rate using decay factor\n",
    "    '''\n",
    "    new_lr = max(current_lr / decay_factor, MIN_LR)\n",
    "    return new_lr\n",
    "\n",
    "def set_learning_rate(new_lr):\n",
    "    '''\n",
    "        Set new learning rate to optimizers\n",
    "    '''\n",
    "    K.set_value(D_optimizer.lr, new_lr)\n",
    "    K.set_value(G_optimizer.lr, new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f510ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoints\n",
    "\n",
    "checkpoint_path = os.path.join(\"checkpoints\", \"tensorflow\", MODEL_NAME)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator=generator,\n",
    "                           discriminator=discriminator,\n",
    "                           G_optimizer=G_optimizer,\n",
    "                           D_optimizer=D_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[1])\n",
    "    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, figure_size=(12,6), subplot=(3,6), save=True, is_flatten=False):\n",
    "    '''\n",
    "        Generate images and plot it.\n",
    "    '''\n",
    "    predictions = model.predict(test_input)\n",
    "    if is_flatten:\n",
    "        predictions = predictions.reshape(-1, IMG_WIDTH, IMG_HEIGHT, 3).astype('float32')\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        axs = plt.subplot(subplot[0], subplot[1], i+1)\n",
    "        plt.imshow(predictions[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 18\n",
    "\n",
    "# We will reuse this seed overtime\n",
    "sample_noise = tf.random.normal([num_examples_to_generate, NOISE_DIM])\n",
    "generate_and_save_images(generator, 0, [sample_noise], figure_size=(12,6), subplot=(3,6), save=False, is_flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set\n",
    "\n",
    "@tf.function\n",
    "def WGAN_GP_train_d_step(real_image, batch_size, step):\n",
    "    '''\n",
    "        One discriminator training step\n",
    "        \n",
    "        Reference: https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "    '''\n",
    "    print(\"retrace\")\n",
    "    noise = tf.random.normal([batch_size, NOISE_DIM])\n",
    "    epsilon = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0, maxval=1)\n",
    "    ###################################\n",
    "    # Train D\n",
    "    ###################################\n",
    "    with tf.GradientTape(persistent=True) as d_tape:\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            fake_image = generator([noise], training=True)\n",
    "            fake_image_mixed = epsilon * tf.dtypes.cast(real_image, tf.float32) + ((1 - epsilon) * fake_image)\n",
    "            fake_mixed_pred = discriminator([fake_image_mixed], training=True)\n",
    "            \n",
    "        # Compute gradient penalty\n",
    "        grads = gp_tape.gradient(fake_mixed_pred, fake_image_mixed)\n",
    "        grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gradient_penalty = tf.reduce_mean(tf.square(grad_norms - 1))\n",
    "        \n",
    "        fake_pred = discriminator([fake_image], training=True)\n",
    "        real_pred = discriminator([real_image], training=True)\n",
    "        \n",
    "        D_loss = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred) + LAMBDA * gradient_penalty\n",
    "    # Calculate the gradients for discriminator\n",
    "    D_gradients = d_tape.gradient(D_loss,\n",
    "                                            discriminator.trainable_variables)\n",
    "    # Apply the gradients to the optimizer\n",
    "    D_optimizer.apply_gradients(zip(D_gradients,\n",
    "                                                discriminator.trainable_variables))\n",
    "    # Write loss values to tensorboard\n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('D_loss', tf.reduce_mean(D_loss), step=step)\n",
    "\n",
    "@tf.function\n",
    "def WGAN_GP_train_g_step(real_image, batch_size, step):\n",
    "    '''\n",
    "        One generator training step\n",
    "        \n",
    "        Reference: https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "    '''\n",
    "    print(\"retrace\")\n",
    "    noise = tf.random.normal([batch_size, NOISE_DIM])\n",
    "    ###################################\n",
    "    # Train G\n",
    "    ###################################\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        fake_image = generator([noise], training=True)\n",
    "        fake_pred = discriminator([fake_image], training=True)\n",
    "        G_loss = -tf.reduce_mean(fake_pred)\n",
    "    # Calculate the gradients for generator\n",
    "    G_gradients = g_tape.gradient(G_loss,\n",
    "                                            generator.trainable_variables)\n",
    "    # Apply the gradients to the optimizer\n",
    "    G_optimizer.apply_gradients(zip(G_gradients,\n",
    "                                                generator.trainable_variables))\n",
    "    # Write loss values to tensorboard\n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('G_loss', G_loss, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "\n",
    "current_learning_rate = LR\n",
    "trace = True\n",
    "n_critic_count = 0\n",
    "\n",
    "for epoch in range(CURRENT_EPOCH, EPOCHs + 1):\n",
    "    start = time.time()\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    # Using learning rate decay\n",
    "    current_learning_rate = learning_rate_decay(current_learning_rate)\n",
    "    print('current_learning_rate %f' % (current_learning_rate,))\n",
    "    set_learning_rate(current_learning_rate)\n",
    "    \n",
    "    for step, (image) in enumerate(train_data):\n",
    "        current_batch_size = image.shape[0]\n",
    "        # Train critic (discriminator)\n",
    "        WGAN_GP_train_d_step(image, batch_size=tf.constant(current_batch_size, dtype=tf.int64), step=tf.constant(step, dtype=tf.int64))\n",
    "        n_critic_count += 1\n",
    "        if n_critic_count >= N_CRITIC: \n",
    "            # Train generator\n",
    "            WGAN_GP_train_g_step(image, batch_size= tf.constant(current_batch_size, dtype=tf.int64), step=tf.constant(step, dtype=tf.int64))\n",
    "            n_critic_count = 0\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print ('.', end='')\n",
    "    \n",
    "    # Clear jupyter notebook cell output\n",
    "    clear_output(wait=True)\n",
    "    # Using a consistent sample so that the progress of the model is clearly visible.\n",
    "    generate_and_save_images(generator, epoch, [sample_noise], figure_size=(12,6), subplot=(3,6), save=True, is_flatten=False)\n",
    "    \n",
    "    if epoch % SAVE_EVERY_N_EPOCH == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch,\n",
    "                                                             ckpt_save_path))\n",
    "    \n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch,\n",
    "                                                      time.time()-start))\n",
    "    \n",
    "# Save at final epoch\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "print ('Saving checkpoint for epoch {} at {}'.format(EPOCHs,\n",
    "                                                        ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0655a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use new sample to see the performance of the model.\n",
    "test_noise = tf.random.normal([64, NOISE_DIM])\n",
    "prediction = generator.predict(test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac78192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(images, fig):\n",
    "    # Create a figure to contain the plot.\n",
    "    for i in range(64):\n",
    "        # Start next subplot.\n",
    "        axs = fig.add_subplot(8, 8, i + 1)\n",
    "        axs.set_xticks([])\n",
    "        axs.set_yticks([])\n",
    "        axs.imshow(np.clip(images[i] * 0.5 + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real images for dataset\n",
    "fig1 = plt.figure(figsize=(12,12))\n",
    "image_grid(sample_img.numpy()[:64], fig1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e167458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fake images from the last epoch\n",
    "fig2 = plt.figure(figsize=(12,12))\n",
    "image_grid(prediction, fig2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
